# Project Milestone #2 - Test + Analysis Milestone

Repository containing work done for Milestone #2 for CSC519-DevOps course

### Submitted by
Name  | Unity ID
------------- | -------------
Arun Jaganathan | ajagana
Balasubramanian Ramesh Babu | bramesh
Kirthika Sekhar | ksekhar
Vivek Mani | vmani2


### Environment

All instances are provisioned as AWS EC2 instances.

    - AMI : ami-965e6bf3
    - Instance type : t2.xlarge
    - Security groups for opening port 8080 (for jetty), port 22 (for ssh) and port 3002 (for checkbox.io)

The script is ran from an ec2 instance. The pem file that is given in the provisioning script is downloaded on to the ansible control server and saved as ec2.key in repo path - inside `~/DevOps_Project`.

### Report

#### Coverage/Jenkins Support

##### Checkbox.io coverage - using HTML report plug in

![image](https://media.github.ncsu.edu/user/5810/files/ea4691e8-2e0f-11e8-952c-b4630f70dc1c)

##### iTrust2 coverage - using Jacoco plug in

![image](https://media.github.ncsu.edu/user/5810/files/077f5326-2e10-11e8-856a-a748fcc29b20) 

#### Fuzzer - by Kirthika Sekhar

- Used the workshop code as a starting point. Removed part of the code that were not needed for fuzzing iTrust2's code and covered all the operations that were needed for the milestone. Made used of the child_process module to execute the git commands directly from nodeJs function. 
- The 4 basic operations in fuzz all most covered all the test cases. For the ones that passed, a detailed inspection into the source code might give us some insights on why they didn't fail.
- In the fuzzing we have done, we have just mirrored some operators/values. This is for sure going to make the test case fail. For majority of the test cases the fuzz results didn't provide us any useful information. In future, its recommended to do fuzzing to discover security flaws/vulnerabilities which makes more sense. 

##### Fuzzer report

![image](https://media.github.ncsu.edu/user/5810/files/b324ff6a-2e0f-11e8-9041-d496d5a5d4c7)

#### Prioritization  Analysis - by Vivek Mani
We looked on the workshop code for reference. Since it just involved normal file parsing and text analysis, we decided to code it using JAVA. Below is a high level overview of the prioritization analysis that were done on the 100 build output files generated by the above fuzzing job.

##### Prioritizing based on the number of failures

Out of the all test cases below are the ones that passed all 100 builds after fuzzing
- **testPersonnelForm**
- **testHospitalForm**
- **testCodes**

The above test cases didn't hit any of the fuzzed code. One possibility is that the functionality that these test cases test didn't have any operations that we have fuzzed. Another is that these test cases always run to SUCCESS. 

##### Prioritizing based on the time taken to execute

Out of the 46 test cases in iTrust2's test suite, **testEmail** test case was the one that took the most time to execute. Since this test case involves connecting to the SMTP server to send out an email we suspect the high time may be due to this additional network overhead, whereas all the other test cases run locally using the machine's resources.

#### Automated test generation for Checkbox.io - by Balasubramanian Ramesh Babu and Arun Jaganathan

- Required to continue the work from the TestGeneration workshop by understanding how Esprima works and how the constraint.js and 
testgenerator.js work to generate testcases in the test.js file.
- We needed to identify a suitable tool to generate coverage reports. Using istanbul was not an accurate solution as it generated a 
coverage report for the test.js file alone.
- Identified istanbul-middleware as the package to be used for generating coverage reports. This required us to generate and index.js 
file that calls the modserver.js file and keeps the server running. Coverage reports are then generated by running the test.js file that is generated and then downloaded.
- We had to understand the traversal of the Esprima tree in order to generate test cases. The earlier workshop had function declarations but the server.js code used here does not have any function declarations. 
- Understand how mongodb works and the databases used by the server.js code. This was particularly helpful when formulating test cases, as we had to figure out that the `site` database had the `studies` and `votes` collections and we needed to insert/delete entries from these using the corresponding object ID.
- In total we generated 21 test cases and achieved a statement coverage of 83.64%.
- We have not covered the test case of uploading a file for a DataStudy. Coverage could have been greater if we had finished that module as well.

### Steps for execution
 
```bash
cd ~
git clone https://github.ncsu.edu/ajagana/DevOps_Project.git
cd DevOps_Project
git checkout m2
ansible-playbook main.yml --vault-password-file vault_pass.txt
```

Make sure to update the ansible vault password in the vault_pass.txt file as well as to have the ec2.key file before running the playbook.

### Screen cast

Here is a [link](https://youtu.be/f0hyI2p2_3U) to the screencast demonstrating the playbook execution and jenkins job checkout explaining all the components of the milestone.

Here is a [link](https://youtu.be/JrO6CpTir0g) to the screencast explaining the repo's code structure and the code for fuzzing and test prioritisation.

Here is a [link](https://youtu.be/0aKbK-gEDmo) to the screencast explaining the code for automated test generation for checkbox.io.
